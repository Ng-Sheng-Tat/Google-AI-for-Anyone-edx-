**Understanding Bad Data**
- data must be well-distributed so that it can generalized better

**What-If Tool** from Google: It aims to let you inspect an ML model with minimal coding required. With this tool, you can inspect the data and the model’s output for that data together. 

**Facets** is a tool that can work in complement to the What-If Tool to give you a deep dive into your data through visualizations. The goal of Facets is to help you understand the distribution of values across features in your dataset. 

**Know Your Data tool** allows you to explore many datasets, but what’s really neat about it is that it uses ML to help understand the data. 
---

**AI Ethics and Bias**

<img src="Steps for Responsible AI.png" alt="Steps for Responsible AI" />

---

- *Responsible* means having a great care towards *fairness, interpretability, privacy, and security*. 

**Responsible AI Practices**
1. Use a human-centered design approach
2. Identify multiple metrics to assess training and monitoring
3. When possible, directly examine your raw data
4. Understand the limitations of your dataset and model
5. Test, Test, Test
6. Continue to monitor and update the system after deployment

---

**Extra Information**

**Google*s AI Principles**
1. Be socially beneficial
2. Avoid creating or reinforcing unfair bias
3. Be built and tested for safety
4. Be accountable to people
5. Incorporate privacy design principles
6. Uphold high standards of scientific excellence 
7. Be made available for uses that accord with these principles 
8. Ensure Benefits outweigh potential risks
9. Avoid creating or reinforcing unfair bias
10. Develop safety and security
